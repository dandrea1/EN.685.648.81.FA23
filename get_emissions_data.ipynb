{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions Data Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Jupyter notebook will pull emissions data from the Environmental Protection Agency (EPA) website. This code will call the EPA API, and will return nationwide carbon monoxide levels. The API only allows the pull of one year of data at a time so we will consolidate at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://aqs.epa.gov/aqsweb/documents/data_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To register for the API:\n",
    "https://aqs.epa.gov/data/api/signup?email=myemail@example.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('14129', 'Lead (TSP) LC'), ('42101', 'Carbon monoxide'), ('42401', 'Sulfur dioxide'), ('42602', 'Nitrogen dioxide (NO2)'), ('44201', 'Ozone'), ('81102', 'PM10 Total 0-10um STP'), ('85129', 'Lead PM10 LC FRM/FEM'), ('88101', 'PM2.5 - Local Conditions')]\n"
     ]
    }
   ],
   "source": [
    "def get_parameter_details():\n",
    "    \"\"\"This function fetches the different EPA measurement parameters and their corresponding codes for use later\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of tuples containing the parameter code and the parameter name\n",
    "    \"\"\"\n",
    "    email = \"test@aqs.api\"\n",
    "    key = \"test\"\n",
    "    pc = \"CRITERIA\"\n",
    "    endpoint = \"https://aqs.epa.gov/data/api/list/parametersByClass\"\n",
    "\n",
    "    params = {\n",
    "        \"email\": email,\n",
    "        \"key\": key,\n",
    "        \"pc\": pc\n",
    "    }\n",
    "\n",
    "    # Check if the response was successful, if so return the data, if not display status code\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()['Data']\n",
    "        # Extracting the parameter name using 'value_represented'\n",
    "        return [(item['code'], item.get('value_represented', None)) for item in data]\n",
    "    else:\n",
    "        print(f\"Failed to fetch parameter details. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "parameter_details = get_parameter_details()\n",
    "print(parameter_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to fetch data for a given state, date range, and parameter\n",
    "def fetch_data_for_state(state, param, bdate, edate):\n",
    "    \"\"\"A function to fetch data for a given state, date range, and parameter\n",
    "    Args:\n",
    "        state ([String]): A list of designated state codes\n",
    "        param (String): The parameter code to fetch data for (Carbon Monoxide, Lead, Ozone, etc.)\n",
    "        bdate (String): The start date to fetch data for\n",
    "        edate (String): The end date to fetch data for\n",
    "    Returns:\n",
    "        json: The data returned by the API in json format\n",
    "    \"\"\"\n",
    "    # Define access parameters\n",
    "    base_url = \"https://aqs.epa.gov/data/api/dailyData/byState\"\n",
    "    email = \"brandonmorrow1010@gmail.com\"  \n",
    "    api_key = \"taupehawk58\"   \n",
    "\n",
    "    # Define the API request parameters\n",
    "    params = {\n",
    "        \"email\": email,\n",
    "        \"key\": api_key,\n",
    "        \"param\": param,\n",
    "        \"bdate\": bdate,\n",
    "        \"edate\": edate,\n",
    "        \"state\": state\n",
    "    }\n",
    "    # Fetch the data\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Check if the response was successful, if so return the data, if not display status code\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed for state {state}. Status code: {response.status_code}\")\n",
    "        print(response.text)  # Print the actual content for debugging\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have everything so lastly we need to clean this up. We want to only keep certain features, so lets define the features and create a cleaning function to clean our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "selected_columns = [\n",
    "    'date_local', 'parameter', 'aqi', 'arithmetic_mean', 'first_max_value',\n",
    "    'sample_duration', 'observation_count', 'observation_percent',\n",
    "    'validity_indicator', 'pollutant_standard'\n",
    "]\n",
    "def clean_emissions_data(df, selected_columns):\n",
    "    \"\"\"Takes in an emissions dataframe and converts it to weekly data\n",
    "    Args:\n",
    "        df (DataFrame): Takes in an emissions dataframe\n",
    "        selected_columns (list): A list of columns to keep\n",
    "    Returns:\n",
    "        DataFrame: Returns a weekly emissions dataframe with filtered columns\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the \"date_local\" column to datetime format\n",
    "    df['date_local'] = pd.to_datetime(df['date_local'], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # Drop rows older than 1/1/2000. \n",
    "    epa_df = df[~(df['date_local'] < '2000-01-01')]\n",
    "\n",
    "    # Group the data by \"date_local\" and calculate daily averages for selected columns\n",
    "    grouped = epa_df.groupby(['date_local'])[selected_columns].mean(numeric_only=True)\n",
    "    daily_aggregated_df = pd.DataFrame(grouped)\n",
    "\n",
    "    # Disaggregate to week level\n",
    "    weekly_epa = daily_aggregated_df.resample('W').ffill()\n",
    "\n",
    "    # Reset the index to make \"date_local\" a regular column\n",
    "    weekly_epa.reset_index(inplace=True)\n",
    "    return weekly_epa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our cleaning function lets get data for all years from \"2000\" to now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for state 01 for year 2017\n",
      "Fetching data for state 02 for year 2017\n",
      "Fetching data for state 03 for year 2017\n",
      "Fetching data for state 04 for year 2017\n",
      "Fetching data for state 05 for year 2017\n",
      "Fetching data for state 06 for year 2017\n",
      "Fetching data for state 07 for year 2017\n",
      "Fetching data for state 08 for year 2017\n",
      "Fetching data for state 09 for year 2017\n",
      "Fetching data for state 10 for year 2017\n",
      "Fetching data for state 11 for year 2017\n",
      "Fetching data for state 12 for year 2017\n",
      "Fetching data for state 13 for year 2017\n",
      "Fetching data for state 14 for year 2017\n",
      "Fetching data for state 15 for year 2017\n",
      "Fetching data for state 16 for year 2017\n",
      "Fetching data for state 17 for year 2017\n",
      "Fetching data for state 18 for year 2017\n",
      "Fetching data for state 19 for year 2017\n",
      "Fetching data for state 20 for year 2017\n",
      "Fetching data for state 21 for year 2017\n",
      "Fetching data for state 22 for year 2017\n",
      "Fetching data for state 23 for year 2017\n",
      "Fetching data for state 24 for year 2017\n",
      "Fetching data for state 25 for year 2017\n",
      "Fetching data for state 26 for year 2017\n",
      "Fetching data for state 27 for year 2017\n",
      "Fetching data for state 28 for year 2017\n",
      "Fetching data for state 29 for year 2017\n",
      "Fetching data for state 30 for year 2017\n",
      "Fetching data for state 31 for year 2017\n",
      "Fetching data for state 32 for year 2017\n",
      "Fetching data for state 33 for year 2017\n",
      "Fetching data for state 34 for year 2017\n",
      "Fetching data for state 35 for year 2017\n",
      "Fetching data for state 36 for year 2017\n",
      "Fetching data for state 37 for year 2017\n",
      "Fetching data for state 38 for year 2017\n",
      "Fetching data for state 39 for year 2017\n",
      "Fetching data for state 40 for year 2017\n",
      "Fetching data for state 41 for year 2017\n",
      "Fetching data for state 42 for year 2017\n",
      "Fetching data for state 43 for year 2017\n",
      "Fetching data for state 44 for year 2017\n",
      "Fetching data for state 45 for year 2017\n",
      "Fetching data for state 46 for year 2017\n",
      "Fetching data for state 47 for year 2017\n",
      "Fetching data for state 48 for year 2017\n",
      "Fetching data for state 49 for year 2017\n",
      "Fetching data for state 50 for year 2017\n",
      "Finished data for year 2017\n",
      "Fetching data for state 01 for year 2018\n",
      "Fetching data for state 02 for year 2018\n",
      "Fetching data for state 03 for year 2018\n",
      "Fetching data for state 04 for year 2018\n",
      "Fetching data for state 05 for year 2018\n",
      "Fetching data for state 06 for year 2018\n",
      "Fetching data for state 07 for year 2018\n",
      "Fetching data for state 08 for year 2018\n",
      "Fetching data for state 09 for year 2018\n",
      "Fetching data for state 10 for year 2018\n",
      "Fetching data for state 11 for year 2018\n",
      "Fetching data for state 12 for year 2018\n",
      "Fetching data for state 13 for year 2018\n",
      "Fetching data for state 14 for year 2018\n",
      "Fetching data for state 15 for year 2018\n",
      "Fetching data for state 16 for year 2018\n",
      "Fetching data for state 17 for year 2018\n",
      "Fetching data for state 18 for year 2018\n",
      "Fetching data for state 19 for year 2018\n",
      "Fetching data for state 20 for year 2018\n",
      "Fetching data for state 21 for year 2018\n",
      "Fetching data for state 22 for year 2018\n",
      "Fetching data for state 23 for year 2018\n",
      "Fetching data for state 24 for year 2018\n",
      "Fetching data for state 25 for year 2018\n",
      "Fetching data for state 26 for year 2018\n",
      "Fetching data for state 27 for year 2018\n",
      "Fetching data for state 28 for year 2018\n",
      "Fetching data for state 29 for year 2018\n",
      "Fetching data for state 30 for year 2018\n",
      "Fetching data for state 31 for year 2018\n",
      "Fetching data for state 32 for year 2018\n",
      "Fetching data for state 33 for year 2018\n",
      "Fetching data for state 34 for year 2018\n",
      "Fetching data for state 35 for year 2018\n",
      "Fetching data for state 36 for year 2018\n",
      "Fetching data for state 37 for year 2018\n",
      "Fetching data for state 38 for year 2018\n",
      "Fetching data for state 39 for year 2018\n",
      "Fetching data for state 40 for year 2018\n",
      "Fetching data for state 41 for year 2018\n",
      "Fetching data for state 42 for year 2018\n",
      "Fetching data for state 43 for year 2018\n",
      "Fetching data for state 44 for year 2018\n",
      "Fetching data for state 45 for year 2018\n",
      "Fetching data for state 46 for year 2018\n",
      "Fetching data for state 47 for year 2018\n",
      "Fetching data for state 48 for year 2018\n",
      "Fetching data for state 49 for year 2018\n",
      "Fetching data for state 50 for year 2018\n",
      "Finished data for year 2018\n",
      "Fetching data for state 01 for year 2019\n",
      "Fetching data for state 02 for year 2019\n",
      "Fetching data for state 03 for year 2019\n",
      "Fetching data for state 04 for year 2019\n",
      "Fetching data for state 05 for year 2019\n",
      "Fetching data for state 06 for year 2019\n",
      "Fetching data for state 07 for year 2019\n",
      "Fetching data for state 08 for year 2019\n",
      "Fetching data for state 09 for year 2019\n",
      "Fetching data for state 10 for year 2019\n",
      "Fetching data for state 11 for year 2019\n",
      "Fetching data for state 12 for year 2019\n",
      "Fetching data for state 13 for year 2019\n",
      "Fetching data for state 14 for year 2019\n",
      "Fetching data for state 15 for year 2019\n",
      "Fetching data for state 16 for year 2019\n",
      "Fetching data for state 17 for year 2019\n",
      "Fetching data for state 18 for year 2019\n",
      "Fetching data for state 19 for year 2019\n",
      "Fetching data for state 20 for year 2019\n",
      "Fetching data for state 21 for year 2019\n",
      "Fetching data for state 22 for year 2019\n",
      "Fetching data for state 23 for year 2019\n",
      "Fetching data for state 24 for year 2019\n",
      "Fetching data for state 25 for year 2019\n",
      "Fetching data for state 26 for year 2019\n",
      "Fetching data for state 27 for year 2019\n",
      "Fetching data for state 28 for year 2019\n",
      "Fetching data for state 29 for year 2019\n",
      "Fetching data for state 30 for year 2019\n",
      "Fetching data for state 31 for year 2019\n",
      "Fetching data for state 32 for year 2019\n",
      "Fetching data for state 33 for year 2019\n",
      "Fetching data for state 34 for year 2019\n",
      "Fetching data for state 35 for year 2019\n",
      "Fetching data for state 36 for year 2019\n",
      "Fetching data for state 37 for year 2019\n",
      "Fetching data for state 38 for year 2019\n",
      "Fetching data for state 39 for year 2019\n",
      "Fetching data for state 40 for year 2019\n",
      "Fetching data for state 41 for year 2019\n",
      "Fetching data for state 42 for year 2019\n",
      "Fetching data for state 43 for year 2019\n",
      "Fetching data for state 44 for year 2019\n",
      "Fetching data for state 45 for year 2019\n",
      "Fetching data for state 46 for year 2019\n",
      "Fetching data for state 47 for year 2019\n",
      "Fetching data for state 48 for year 2019\n",
      "Fetching data for state 49 for year 2019\n",
      "Fetching data for state 50 for year 2019\n",
      "Finished data for year 2019\n",
      "Fetching data for state 01 for year 2020\n",
      "Fetching data for state 02 for year 2020\n",
      "Fetching data for state 03 for year 2020\n",
      "Fetching data for state 04 for year 2020\n",
      "Fetching data for state 05 for year 2020\n",
      "Fetching data for state 06 for year 2020\n",
      "Fetching data for state 07 for year 2020\n",
      "Fetching data for state 08 for year 2020\n",
      "Fetching data for state 09 for year 2020\n",
      "Fetching data for state 10 for year 2020\n",
      "Failed for state 11. Status code: 502\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>502 Proxy Error</title>\n",
      "</head><body>\n",
      "<h1>Proxy Error</h1>\n",
      "<p>The proxy server received an invalid\n",
      "response from an upstream server.<br />\n",
      "The proxy server could not handle the request<p>Reason: <strong>Error reading from remote server</strong></p></p>\n",
      "<p>Additionally, a 502 Bad Gateway\n",
      "error was encountered while trying to use an ErrorDocument to handle the request.</p>\n",
      "</body></html>\n",
      "\n",
      "Fetching data for state 11 for year 2020\n",
      "Fetching data for state 12 for year 2020\n",
      "Fetching data for state 13 for year 2020\n",
      "Fetching data for state 14 for year 2020\n",
      "Fetching data for state 15 for year 2020\n",
      "Fetching data for state 16 for year 2020\n",
      "Fetching data for state 17 for year 2020\n",
      "Fetching data for state 18 for year 2020\n",
      "Fetching data for state 19 for year 2020\n",
      "Fetching data for state 20 for year 2020\n",
      "Fetching data for state 21 for year 2020\n",
      "Fetching data for state 22 for year 2020\n",
      "Fetching data for state 23 for year 2020\n",
      "Fetching data for state 24 for year 2020\n",
      "Fetching data for state 25 for year 2020\n",
      "Fetching data for state 26 for year 2020\n",
      "Fetching data for state 27 for year 2020\n",
      "Fetching data for state 28 for year 2020\n",
      "Fetching data for state 29 for year 2020\n",
      "Fetching data for state 30 for year 2020\n",
      "Fetching data for state 31 for year 2020\n",
      "Fetching data for state 32 for year 2020\n",
      "Fetching data for state 33 for year 2020\n",
      "Fetching data for state 34 for year 2020\n",
      "Fetching data for state 35 for year 2020\n",
      "Fetching data for state 36 for year 2020\n",
      "Fetching data for state 37 for year 2020\n",
      "Fetching data for state 38 for year 2020\n",
      "Fetching data for state 39 for year 2020\n",
      "Fetching data for state 40 for year 2020\n",
      "Fetching data for state 41 for year 2020\n",
      "Fetching data for state 42 for year 2020\n",
      "Fetching data for state 43 for year 2020\n",
      "Fetching data for state 44 for year 2020\n",
      "Fetching data for state 45 for year 2020\n",
      "Fetching data for state 46 for year 2020\n",
      "Fetching data for state 47 for year 2020\n",
      "Fetching data for state 48 for year 2020\n",
      "Fetching data for state 49 for year 2020\n",
      "Fetching data for state 50 for year 2020\n",
      "Finished data for year 2020\n",
      "Fetching data for state 01 for year 2021\n",
      "Fetching data for state 02 for year 2021\n",
      "Fetching data for state 03 for year 2021\n",
      "Fetching data for state 04 for year 2021\n",
      "Fetching data for state 05 for year 2021\n",
      "Fetching data for state 06 for year 2021\n",
      "Fetching data for state 07 for year 2021\n",
      "Fetching data for state 08 for year 2021\n",
      "Fetching data for state 09 for year 2021\n",
      "Fetching data for state 10 for year 2021\n",
      "Fetching data for state 11 for year 2021\n",
      "Fetching data for state 12 for year 2021\n",
      "Fetching data for state 13 for year 2021\n",
      "Fetching data for state 14 for year 2021\n",
      "Fetching data for state 15 for year 2021\n",
      "Fetching data for state 16 for year 2021\n",
      "Fetching data for state 17 for year 2021\n",
      "Fetching data for state 18 for year 2021\n",
      "Fetching data for state 19 for year 2021\n",
      "Fetching data for state 20 for year 2021\n",
      "Fetching data for state 21 for year 2021\n",
      "Fetching data for state 22 for year 2021\n",
      "Fetching data for state 23 for year 2021\n",
      "Fetching data for state 24 for year 2021\n",
      "Fetching data for state 25 for year 2021\n",
      "Fetching data for state 26 for year 2021\n",
      "Fetching data for state 27 for year 2021\n",
      "Fetching data for state 28 for year 2021\n",
      "Fetching data for state 29 for year 2021\n",
      "Fetching data for state 30 for year 2021\n",
      "Fetching data for state 31 for year 2021\n",
      "Fetching data for state 32 for year 2021\n",
      "Fetching data for state 33 for year 2021\n",
      "Fetching data for state 34 for year 2021\n",
      "Fetching data for state 35 for year 2021\n",
      "Fetching data for state 36 for year 2021\n",
      "Fetching data for state 37 for year 2021\n",
      "Fetching data for state 38 for year 2021\n",
      "Fetching data for state 39 for year 2021\n",
      "Fetching data for state 40 for year 2021\n",
      "Fetching data for state 41 for year 2021\n",
      "Fetching data for state 42 for year 2021\n",
      "Fetching data for state 43 for year 2021\n",
      "Fetching data for state 44 for year 2021\n",
      "Fetching data for state 45 for year 2021\n",
      "Fetching data for state 46 for year 2021\n",
      "Fetching data for state 47 for year 2021\n",
      "Fetching data for state 48 for year 2021\n",
      "Fetching data for state 49 for year 2021\n",
      "Fetching data for state 50 for year 2021\n",
      "Finished data for year 2021\n",
      "Fetching data for state 01 for year 2022\n",
      "Fetching data for state 02 for year 2022\n",
      "Fetching data for state 03 for year 2022\n",
      "Fetching data for state 04 for year 2022\n",
      "Fetching data for state 05 for year 2022\n",
      "Fetching data for state 06 for year 2022\n",
      "Fetching data for state 07 for year 2022\n",
      "Fetching data for state 08 for year 2022\n",
      "Fetching data for state 09 for year 2022\n",
      "Fetching data for state 10 for year 2022\n",
      "Fetching data for state 11 for year 2022\n",
      "Fetching data for state 12 for year 2022\n",
      "Fetching data for state 13 for year 2022\n",
      "Fetching data for state 14 for year 2022\n",
      "Fetching data for state 15 for year 2022\n",
      "Fetching data for state 16 for year 2022\n",
      "Fetching data for state 17 for year 2022\n",
      "Fetching data for state 18 for year 2022\n",
      "Fetching data for state 19 for year 2022\n",
      "Fetching data for state 20 for year 2022\n",
      "Fetching data for state 21 for year 2022\n",
      "Fetching data for state 22 for year 2022\n",
      "Fetching data for state 23 for year 2022\n",
      "Fetching data for state 24 for year 2022\n",
      "Fetching data for state 25 for year 2022\n",
      "Fetching data for state 26 for year 2022\n",
      "Fetching data for state 27 for year 2022\n",
      "Fetching data for state 28 for year 2022\n",
      "Fetching data for state 29 for year 2022\n",
      "Fetching data for state 30 for year 2022\n",
      "Fetching data for state 31 for year 2022\n",
      "Fetching data for state 32 for year 2022\n",
      "Fetching data for state 33 for year 2022\n",
      "Fetching data for state 34 for year 2022\n",
      "Fetching data for state 35 for year 2022\n",
      "Fetching data for state 36 for year 2022\n",
      "Fetching data for state 37 for year 2022\n",
      "Fetching data for state 38 for year 2022\n",
      "Fetching data for state 39 for year 2022\n",
      "Fetching data for state 40 for year 2022\n",
      "Fetching data for state 41 for year 2022\n",
      "Fetching data for state 42 for year 2022\n",
      "Fetching data for state 43 for year 2022\n",
      "Fetching data for state 44 for year 2022\n",
      "Fetching data for state 45 for year 2022\n",
      "Fetching data for state 46 for year 2022\n",
      "Fetching data for state 47 for year 2022\n",
      "Fetching data for state 48 for year 2022\n",
      "Fetching data for state 49 for year 2022\n",
      "Fetching data for state 50 for year 2022\n",
      "Finished data for year 2022\n",
      "Fetching data for state 01 for year 2023\n",
      "Fetching data for state 02 for year 2023\n",
      "Fetching data for state 03 for year 2023\n",
      "Fetching data for state 04 for year 2023\n",
      "Fetching data for state 05 for year 2023\n",
      "Fetching data for state 06 for year 2023\n",
      "Fetching data for state 07 for year 2023\n",
      "Fetching data for state 08 for year 2023\n",
      "Fetching data for state 09 for year 2023\n",
      "Fetching data for state 10 for year 2023\n",
      "Fetching data for state 11 for year 2023\n",
      "Fetching data for state 12 for year 2023\n",
      "Fetching data for state 13 for year 2023\n",
      "Fetching data for state 14 for year 2023\n",
      "Fetching data for state 15 for year 2023\n",
      "Fetching data for state 16 for year 2023\n",
      "Fetching data for state 17 for year 2023\n",
      "Fetching data for state 18 for year 2023\n",
      "Fetching data for state 19 for year 2023\n",
      "Fetching data for state 20 for year 2023\n",
      "Fetching data for state 21 for year 2023\n",
      "Fetching data for state 22 for year 2023\n",
      "Fetching data for state 23 for year 2023\n",
      "Fetching data for state 24 for year 2023\n",
      "Fetching data for state 25 for year 2023\n",
      "Fetching data for state 26 for year 2023\n",
      "Fetching data for state 27 for year 2023\n",
      "Fetching data for state 28 for year 2023\n",
      "Fetching data for state 29 for year 2023\n",
      "Fetching data for state 30 for year 2023\n",
      "Fetching data for state 31 for year 2023\n",
      "Fetching data for state 32 for year 2023\n",
      "Fetching data for state 33 for year 2023\n",
      "Fetching data for state 34 for year 2023\n",
      "Fetching data for state 35 for year 2023\n",
      "Fetching data for state 36 for year 2023\n",
      "Fetching data for state 37 for year 2023\n",
      "Fetching data for state 38 for year 2023\n",
      "Fetching data for state 39 for year 2023\n",
      "Fetching data for state 40 for year 2023\n",
      "Fetching data for state 41 for year 2023\n",
      "Fetching data for state 42 for year 2023\n",
      "Fetching data for state 43 for year 2023\n",
      "Fetching data for state 44 for year 2023\n",
      "Fetching data for state 45 for year 2023\n",
      "Fetching data for state 46 for year 2023\n",
      "Fetching data for state 47 for year 2023\n",
      "Fetching data for state 48 for year 2023\n",
      "Fetching data for state 49 for year 2023\n",
      "Fetching data for state 50 for year 2023\n",
      "Finished data for year 2023\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters\n",
    "param = \"42101\"  # Carbon Monoxide\n",
    "state_codes = [\n",
    "    '01', '02', '03', '04', '05', '06', '07', '08', '09', '10',\n",
    "    '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',\n",
    "    '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',\n",
    "    '31', '32', '33', '34', '35', '36', '37', '38', '39', '40',\n",
    "    '41', '42', '43', '44', '45', '46', '47', '48', '49', '50'\n",
    "] # All states\n",
    "\n",
    "# Get years 2017-2023\n",
    "years = [\"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "\n",
    "weekly_emissions_all_years = pd.DataFrame()\n",
    "for year in years:\n",
    "    if year == \"2023\":\n",
    "        bdate = year + \"0611\"\n",
    "        edate = year + \"1231\"\n",
    "    else:\n",
    "        bdate = year + \"0101\"\n",
    "        edate = year + \"1231\"\n",
    "\n",
    "    all_states_data = []\n",
    "    for state_code in state_codes:\n",
    "        data = fetch_data_for_state(state_code, param, bdate, edate)\n",
    "        print(f\"Fetching data for state {state_code} for year {year}\")\n",
    "        # Check if data is not null and contains key 'Data', if so then add to list of data\n",
    "        if data and 'Data' in data: \n",
    "            all_states_data.extend(data['Data'])\n",
    "\n",
    "    df = pd.DataFrame(all_states_data) # Convert to pandas DataFrame\n",
    "    weekly_epa = clean_emissions_data(df, selected_columns)  # Clean the data\n",
    "    weekly_emissions_all_years = pd.concat([weekly_emissions_all_years, weekly_epa], ignore_index=True) # Add to the main dataframe\n",
    "    print(f\"Finished data for year {year}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good lets check what features we got from our request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 340 entries, 0 to 339\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date_local           340 non-null    datetime64[ns]\n",
      " 1   aqi                  340 non-null    float64       \n",
      " 2   arithmetic_mean      340 non-null    float64       \n",
      " 3   first_max_value      340 non-null    float64       \n",
      " 4   observation_count    340 non-null    float64       \n",
      " 5   observation_percent  340 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 16.1 KB\n"
     ]
    }
   ],
   "source": [
    "weekly_emissions_all_years.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are too many features here so we will pull the features that we want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_local</th>\n",
       "      <th>aqi</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>first_max_value</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>5.253676</td>\n",
       "      <td>0.320456</td>\n",
       "      <td>0.549016</td>\n",
       "      <td>21.429616</td>\n",
       "      <td>87.259598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>5.343284</td>\n",
       "      <td>0.335255</td>\n",
       "      <td>0.532002</td>\n",
       "      <td>24.005576</td>\n",
       "      <td>98.016729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>5.616236</td>\n",
       "      <td>0.345083</td>\n",
       "      <td>0.561547</td>\n",
       "      <td>24.018416</td>\n",
       "      <td>98.097606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>5.047619</td>\n",
       "      <td>0.294642</td>\n",
       "      <td>0.490790</td>\n",
       "      <td>24.080439</td>\n",
       "      <td>98.365631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>5.408088</td>\n",
       "      <td>0.328773</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>24.069725</td>\n",
       "      <td>98.313761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_local       aqi  arithmetic_mean  first_max_value  observation_count  \\\n",
       "0 2017-01-01  5.253676         0.320456         0.549016          21.429616   \n",
       "1 2017-01-08  5.343284         0.335255         0.532002          24.005576   \n",
       "2 2017-01-15  5.616236         0.345083         0.561547          24.018416   \n",
       "3 2017-01-22  5.047619         0.294642         0.490790          24.080439   \n",
       "4 2017-01-29  5.408088         0.328773         0.553846          24.069725   \n",
       "\n",
       "   observation_percent  \n",
       "0            87.259598  \n",
       "1            98.016729  \n",
       "2            98.097606  \n",
       "3            98.365631  \n",
       "4            98.313761  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_emissions_all_years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final df to csv\n",
    "weekly_emissions_all_years.to_csv(\"emissions_data_2017_2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_epa.to_csv(\"detailed_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
