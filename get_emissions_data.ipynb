{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emissions Data Pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Jupyter notebook will pull emissions data from the Environmental Protection Agency (EPA) website. This code will call the EPA API, and will return nationwide carbon monoxide levels. The API only allows the pull of one year of data at a time so we will consolidate at the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer: This code takes a while to pull data(~2 hrs) from 2017 as the API only allows one request at a time, and no asynchronous calls. The weekly update airflow script runs much faster. This is a one time pull to our database, and then there are weekly updates in airflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://aqs.epa.gov/aqsweb/documents/data_api.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To register for the API:\n",
    "https://aqs.epa.gov/data/api/signup?email=myemail@example.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('14129', 'Lead (TSP) LC'), ('42101', 'Carbon monoxide'), ('42401', 'Sulfur dioxide'), ('42602', 'Nitrogen dioxide (NO2)'), ('44201', 'Ozone'), ('81102', 'PM10 Total 0-10um STP'), ('85129', 'Lead PM10 LC FRM/FEM'), ('88101', 'PM2.5 - Local Conditions')]\n"
     ]
    }
   ],
   "source": [
    "def get_parameter_details():\n",
    "    \"\"\"This function fetches the different EPA measurement parameters and their corresponding codes for use later\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of tuples containing the parameter code and the parameter name\n",
    "    \"\"\"\n",
    "    email = \"test@aqs.api\"\n",
    "    key = \"test\"\n",
    "    pc = \"CRITERIA\"\n",
    "    endpoint = \"https://aqs.epa.gov/data/api/list/parametersByClass\"\n",
    "\n",
    "    params = {\n",
    "        \"email\": email,\n",
    "        \"key\": key,\n",
    "        \"pc\": pc\n",
    "    }\n",
    "\n",
    "    # Check if the response was successful, if so return the data, if not display status code\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()['Data']\n",
    "        # Extracting the parameter name using 'value_represented'\n",
    "        return [(item['code'], item.get('value_represented', None)) for item in data]\n",
    "    else:\n",
    "        print(f\"Failed to fetch parameter details. Status code: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "parameter_details = get_parameter_details()\n",
    "print(parameter_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a function to fetch data for a given state, date range, and parameter\n",
    "def fetch_data_for_state(state, param, bdate, edate):\n",
    "    \"\"\"A function to fetch data for a given state, date range, and parameter\n",
    "    Args:\n",
    "        state ([String]): A list of designated state codes\n",
    "        param (String): The parameter code to fetch data for (Carbon Monoxide, Lead, Ozone, etc.)\n",
    "        bdate (String): The start date to fetch data for\n",
    "        edate (String): The end date to fetch data for\n",
    "    Returns:\n",
    "        json: The data returned by the API in json format\n",
    "    \"\"\"\n",
    "    # Define access parameters\n",
    "    base_url = \"https://aqs.epa.gov/data/api/dailyData/byState\"\n",
    "    email = \"brandonmorrow1010@gmail.com\"  \n",
    "    api_key = \"taupehawk58\"   # Please dont steal my api key and put me on a watch list\n",
    "\n",
    "    # Define the API request parameters\n",
    "    params = {\n",
    "        \"email\": email,\n",
    "        \"key\": api_key,\n",
    "        \"param\": param,\n",
    "        \"bdate\": bdate,\n",
    "        \"edate\": edate,\n",
    "        \"state\": state\n",
    "    }\n",
    "    # Fetch the data\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    # Check if the response was successful, if so return the data, if not display status code\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Failed for state {state}. Status code: {response.status_code}\")\n",
    "        print(response.text)  # Print the actual content for debugging\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have everything so lastly we need to clean this up. We want to only keep certain features, so lets define the features and create a cleaning function to clean our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_emissions_data(df, selected_columns):\n",
    "    \"\"\"Takes in an emissions dataframe and converts it to weekly data\n",
    "    Args:\n",
    "        df (DataFrame): Takes in an emissions dataframe\n",
    "        selected_columns (list): A list of columns to keep\n",
    "    Returns:\n",
    "        DataFrame: Returns a weekly emissions dataframe with filtered columns\n",
    "    \"\"\"    \n",
    "    # Convert the \"date_local\" column to datetime format\n",
    "    df['date_local'] = pd.to_datetime(df['date_local'], format=\"%Y-%m-%d\")\n",
    "\n",
    "    # Group the data by \"date_local\" and calculate daily averages for selected columns\n",
    "    grouped = df.groupby(['date_local'])[selected_columns].mean(numeric_only=True)\n",
    "    daily_aggregated_df = pd.DataFrame(grouped).round(4)\n",
    "\n",
    "    # Disaggregate to week level\n",
    "    weekly_epa = daily_aggregated_df.resample('W').ffill()\n",
    "\n",
    "    # Reset the index to make \"date_local\" a regular column\n",
    "    weekly_epa.reset_index(inplace=True)\n",
    "    return weekly_epa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our cleaning function lets get data for all years from \"2017\" to now.  This takes a while as the API is a free government API which does not allow synchornous calls so the calls must be made one after the other. We can only get data by state by day. So to get the national average we must take all of this data and then clean it with our above cleaning function. We also define the selected columns that we want for analysis. We will then save this data into two files. One file for the total data, and one file for the processed weekly data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for state 01 for year 2017\n",
      "Fetching data for state 02 for year 2017\n",
      "Fetching data for state 03 for year 2017\n",
      "Fetching data for state 04 for year 2017\n",
      "Fetching data for state 05 for year 2017\n",
      "Fetching data for state 06 for year 2017\n",
      "Fetching data for state 07 for year 2017\n",
      "Fetching data for state 08 for year 2017\n",
      "Fetching data for state 09 for year 2017\n",
      "Fetching data for state 10 for year 2017\n",
      "Fetching data for state 11 for year 2017\n",
      "Fetching data for state 12 for year 2017\n",
      "Fetching data for state 13 for year 2017\n",
      "Fetching data for state 14 for year 2017\n",
      "Fetching data for state 15 for year 2017\n",
      "Fetching data for state 16 for year 2017\n",
      "Fetching data for state 17 for year 2017\n",
      "Fetching data for state 18 for year 2017\n",
      "Fetching data for state 19 for year 2017\n",
      "Fetching data for state 20 for year 2017\n",
      "Fetching data for state 21 for year 2017\n",
      "Fetching data for state 22 for year 2017\n",
      "Fetching data for state 23 for year 2017\n",
      "Fetching data for state 24 for year 2017\n",
      "Fetching data for state 25 for year 2017\n",
      "Fetching data for state 26 for year 2017\n",
      "Fetching data for state 27 for year 2017\n",
      "Fetching data for state 28 for year 2017\n",
      "Fetching data for state 29 for year 2017\n",
      "Fetching data for state 30 for year 2017\n",
      "Fetching data for state 31 for year 2017\n",
      "Fetching data for state 32 for year 2017\n",
      "Fetching data for state 33 for year 2017\n",
      "Fetching data for state 34 for year 2017\n",
      "Fetching data for state 35 for year 2017\n",
      "Fetching data for state 36 for year 2017\n",
      "Fetching data for state 37 for year 2017\n",
      "Fetching data for state 38 for year 2017\n",
      "Fetching data for state 39 for year 2017\n",
      "Fetching data for state 40 for year 2017\n",
      "Fetching data for state 41 for year 2017\n",
      "Fetching data for state 42 for year 2017\n",
      "Fetching data for state 43 for year 2017\n",
      "Fetching data for state 44 for year 2017\n",
      "Fetching data for state 45 for year 2017\n",
      "Fetching data for state 46 for year 2017\n",
      "Fetching data for state 47 for year 2017\n",
      "Fetching data for state 48 for year 2017\n",
      "Fetching data for state 49 for year 2017\n",
      "Fetching data for state 50 for year 2017\n",
      "Finished data for year 2017\n",
      "Fetching data for state 01 for year 2018\n",
      "Fetching data for state 02 for year 2018\n",
      "Fetching data for state 03 for year 2018\n",
      "Fetching data for state 04 for year 2018\n",
      "Fetching data for state 05 for year 2018\n",
      "Fetching data for state 06 for year 2018\n",
      "Fetching data for state 07 for year 2018\n",
      "Fetching data for state 08 for year 2018\n",
      "Fetching data for state 09 for year 2018\n",
      "Fetching data for state 10 for year 2018\n",
      "Fetching data for state 11 for year 2018\n",
      "Fetching data for state 12 for year 2018\n",
      "Fetching data for state 13 for year 2018\n",
      "Fetching data for state 14 for year 2018\n",
      "Fetching data for state 15 for year 2018\n",
      "Fetching data for state 16 for year 2018\n",
      "Fetching data for state 17 for year 2018\n",
      "Fetching data for state 18 for year 2018\n",
      "Fetching data for state 19 for year 2018\n",
      "Fetching data for state 20 for year 2018\n",
      "Fetching data for state 21 for year 2018\n",
      "Fetching data for state 22 for year 2018\n",
      "Fetching data for state 23 for year 2018\n",
      "Fetching data for state 24 for year 2018\n",
      "Fetching data for state 25 for year 2018\n",
      "Fetching data for state 26 for year 2018\n",
      "Fetching data for state 27 for year 2018\n",
      "Fetching data for state 28 for year 2018\n",
      "Fetching data for state 29 for year 2018\n",
      "Fetching data for state 30 for year 2018\n",
      "Fetching data for state 31 for year 2018\n",
      "Fetching data for state 32 for year 2018\n",
      "Fetching data for state 33 for year 2018\n",
      "Fetching data for state 34 for year 2018\n",
      "Fetching data for state 35 for year 2018\n",
      "Fetching data for state 36 for year 2018\n",
      "Fetching data for state 37 for year 2018\n",
      "Fetching data for state 38 for year 2018\n",
      "Fetching data for state 39 for year 2018\n",
      "Fetching data for state 40 for year 2018\n",
      "Fetching data for state 41 for year 2018\n",
      "Fetching data for state 42 for year 2018\n",
      "Fetching data for state 43 for year 2018\n",
      "Fetching data for state 44 for year 2018\n",
      "Fetching data for state 45 for year 2018\n",
      "Fetching data for state 46 for year 2018\n",
      "Fetching data for state 47 for year 2018\n",
      "Fetching data for state 48 for year 2018\n",
      "Fetching data for state 49 for year 2018\n",
      "Fetching data for state 50 for year 2018\n",
      "Finished data for year 2018\n",
      "Fetching data for state 01 for year 2019\n",
      "Fetching data for state 02 for year 2019\n",
      "Fetching data for state 03 for year 2019\n",
      "Fetching data for state 04 for year 2019\n",
      "Fetching data for state 05 for year 2019\n",
      "Fetching data for state 06 for year 2019\n",
      "Fetching data for state 07 for year 2019\n",
      "Fetching data for state 08 for year 2019\n",
      "Fetching data for state 09 for year 2019\n",
      "Fetching data for state 10 for year 2019\n",
      "Fetching data for state 11 for year 2019\n",
      "Fetching data for state 12 for year 2019\n",
      "Fetching data for state 13 for year 2019\n",
      "Fetching data for state 14 for year 2019\n",
      "Fetching data for state 15 for year 2019\n",
      "Fetching data for state 16 for year 2019\n",
      "Fetching data for state 17 for year 2019\n",
      "Fetching data for state 18 for year 2019\n",
      "Fetching data for state 19 for year 2019\n",
      "Fetching data for state 20 for year 2019\n",
      "Fetching data for state 21 for year 2019\n",
      "Fetching data for state 22 for year 2019\n",
      "Fetching data for state 23 for year 2019\n",
      "Fetching data for state 24 for year 2019\n",
      "Fetching data for state 25 for year 2019\n",
      "Fetching data for state 26 for year 2019\n",
      "Fetching data for state 27 for year 2019\n",
      "Fetching data for state 28 for year 2019\n",
      "Fetching data for state 29 for year 2019\n",
      "Fetching data for state 30 for year 2019\n",
      "Fetching data for state 31 for year 2019\n",
      "Fetching data for state 32 for year 2019\n",
      "Fetching data for state 33 for year 2019\n",
      "Fetching data for state 34 for year 2019\n",
      "Fetching data for state 35 for year 2019\n",
      "Fetching data for state 36 for year 2019\n",
      "Fetching data for state 37 for year 2019\n",
      "Fetching data for state 38 for year 2019\n",
      "Fetching data for state 39 for year 2019\n",
      "Fetching data for state 40 for year 2019\n",
      "Fetching data for state 41 for year 2019\n",
      "Fetching data for state 42 for year 2019\n",
      "Fetching data for state 43 for year 2019\n",
      "Fetching data for state 44 for year 2019\n",
      "Fetching data for state 45 for year 2019\n",
      "Fetching data for state 46 for year 2019\n",
      "Fetching data for state 47 for year 2019\n",
      "Fetching data for state 48 for year 2019\n",
      "Fetching data for state 49 for year 2019\n",
      "Fetching data for state 50 for year 2019\n",
      "Finished data for year 2019\n",
      "Fetching data for state 01 for year 2020\n",
      "Fetching data for state 02 for year 2020\n",
      "Fetching data for state 03 for year 2020\n",
      "Fetching data for state 04 for year 2020\n",
      "Fetching data for state 05 for year 2020\n",
      "Fetching data for state 06 for year 2020\n",
      "Fetching data for state 07 for year 2020\n",
      "Fetching data for state 08 for year 2020\n",
      "Fetching data for state 09 for year 2020\n",
      "Fetching data for state 10 for year 2020\n",
      "Fetching data for state 11 for year 2020\n",
      "Fetching data for state 12 for year 2020\n",
      "Fetching data for state 13 for year 2020\n",
      "Fetching data for state 14 for year 2020\n",
      "Fetching data for state 15 for year 2020\n",
      "Fetching data for state 16 for year 2020\n",
      "Fetching data for state 17 for year 2020\n",
      "Fetching data for state 18 for year 2020\n",
      "Fetching data for state 19 for year 2020\n",
      "Fetching data for state 20 for year 2020\n",
      "Fetching data for state 21 for year 2020\n",
      "Fetching data for state 22 for year 2020\n",
      "Fetching data for state 23 for year 2020\n",
      "Fetching data for state 24 for year 2020\n",
      "Fetching data for state 25 for year 2020\n",
      "Fetching data for state 26 for year 2020\n",
      "Fetching data for state 27 for year 2020\n",
      "Fetching data for state 28 for year 2020\n",
      "Fetching data for state 29 for year 2020\n",
      "Fetching data for state 30 for year 2020\n",
      "Fetching data for state 31 for year 2020\n",
      "Fetching data for state 32 for year 2020\n",
      "Fetching data for state 33 for year 2020\n",
      "Fetching data for state 34 for year 2020\n",
      "Fetching data for state 35 for year 2020\n",
      "Fetching data for state 36 for year 2020\n",
      "Fetching data for state 37 for year 2020\n",
      "Fetching data for state 38 for year 2020\n",
      "Fetching data for state 39 for year 2020\n",
      "Fetching data for state 40 for year 2020\n",
      "Fetching data for state 41 for year 2020\n",
      "Fetching data for state 42 for year 2020\n",
      "Fetching data for state 43 for year 2020\n",
      "Fetching data for state 44 for year 2020\n",
      "Fetching data for state 45 for year 2020\n",
      "Fetching data for state 46 for year 2020\n",
      "Fetching data for state 47 for year 2020\n",
      "Fetching data for state 48 for year 2020\n",
      "Fetching data for state 49 for year 2020\n",
      "Fetching data for state 50 for year 2020\n",
      "Finished data for year 2020\n",
      "Fetching data for state 01 for year 2021\n",
      "Fetching data for state 02 for year 2021\n",
      "Fetching data for state 03 for year 2021\n",
      "Fetching data for state 04 for year 2021\n",
      "Fetching data for state 05 for year 2021\n",
      "Fetching data for state 06 for year 2021\n",
      "Fetching data for state 07 for year 2021\n",
      "Fetching data for state 08 for year 2021\n",
      "Fetching data for state 09 for year 2021\n",
      "Fetching data for state 10 for year 2021\n",
      "Fetching data for state 11 for year 2021\n",
      "Fetching data for state 12 for year 2021\n",
      "Fetching data for state 13 for year 2021\n",
      "Fetching data for state 14 for year 2021\n",
      "Fetching data for state 15 for year 2021\n",
      "Fetching data for state 16 for year 2021\n",
      "Fetching data for state 17 for year 2021\n",
      "Fetching data for state 18 for year 2021\n",
      "Fetching data for state 19 for year 2021\n",
      "Fetching data for state 20 for year 2021\n",
      "Fetching data for state 21 for year 2021\n",
      "Fetching data for state 22 for year 2021\n",
      "Fetching data for state 23 for year 2021\n",
      "Fetching data for state 24 for year 2021\n",
      "Fetching data for state 25 for year 2021\n",
      "Fetching data for state 26 for year 2021\n",
      "Fetching data for state 27 for year 2021\n",
      "Fetching data for state 28 for year 2021\n",
      "Fetching data for state 29 for year 2021\n",
      "Fetching data for state 30 for year 2021\n",
      "Fetching data for state 31 for year 2021\n",
      "Fetching data for state 32 for year 2021\n",
      "Fetching data for state 33 for year 2021\n",
      "Fetching data for state 34 for year 2021\n",
      "Fetching data for state 35 for year 2021\n",
      "Fetching data for state 36 for year 2021\n",
      "Fetching data for state 37 for year 2021\n",
      "Fetching data for state 38 for year 2021\n",
      "Fetching data for state 39 for year 2021\n",
      "Fetching data for state 40 for year 2021\n",
      "Fetching data for state 41 for year 2021\n",
      "Fetching data for state 42 for year 2021\n",
      "Fetching data for state 43 for year 2021\n",
      "Fetching data for state 44 for year 2021\n",
      "Fetching data for state 45 for year 2021\n",
      "Fetching data for state 46 for year 2021\n",
      "Fetching data for state 47 for year 2021\n",
      "Fetching data for state 48 for year 2021\n",
      "Fetching data for state 49 for year 2021\n",
      "Fetching data for state 50 for year 2021\n",
      "Finished data for year 2021\n",
      "Fetching data for state 01 for year 2022\n",
      "Fetching data for state 02 for year 2022\n",
      "Fetching data for state 03 for year 2022\n",
      "Fetching data for state 04 for year 2022\n",
      "Fetching data for state 05 for year 2022\n",
      "Fetching data for state 06 for year 2022\n",
      "Fetching data for state 07 for year 2022\n",
      "Fetching data for state 08 for year 2022\n",
      "Fetching data for state 09 for year 2022\n",
      "Fetching data for state 10 for year 2022\n",
      "Fetching data for state 11 for year 2022\n",
      "Fetching data for state 12 for year 2022\n",
      "Fetching data for state 13 for year 2022\n",
      "Fetching data for state 14 for year 2022\n",
      "Fetching data for state 15 for year 2022\n",
      "Fetching data for state 16 for year 2022\n",
      "Fetching data for state 17 for year 2022\n",
      "Fetching data for state 18 for year 2022\n",
      "Fetching data for state 19 for year 2022\n",
      "Fetching data for state 20 for year 2022\n",
      "Fetching data for state 21 for year 2022\n",
      "Fetching data for state 22 for year 2022\n",
      "Fetching data for state 23 for year 2022\n",
      "Fetching data for state 24 for year 2022\n",
      "Fetching data for state 25 for year 2022\n",
      "Fetching data for state 26 for year 2022\n",
      "Fetching data for state 27 for year 2022\n",
      "Fetching data for state 28 for year 2022\n",
      "Fetching data for state 29 for year 2022\n",
      "Fetching data for state 30 for year 2022\n",
      "Fetching data for state 31 for year 2022\n",
      "Fetching data for state 32 for year 2022\n",
      "Fetching data for state 33 for year 2022\n",
      "Fetching data for state 34 for year 2022\n",
      "Fetching data for state 35 for year 2022\n",
      "Fetching data for state 36 for year 2022\n",
      "Fetching data for state 37 for year 2022\n",
      "Fetching data for state 38 for year 2022\n",
      "Fetching data for state 39 for year 2022\n",
      "Fetching data for state 40 for year 2022\n",
      "Fetching data for state 41 for year 2022\n",
      "Fetching data for state 42 for year 2022\n",
      "Fetching data for state 43 for year 2022\n",
      "Fetching data for state 44 for year 2022\n",
      "Fetching data for state 45 for year 2022\n",
      "Fetching data for state 46 for year 2022\n",
      "Fetching data for state 47 for year 2022\n",
      "Fetching data for state 48 for year 2022\n",
      "Fetching data for state 49 for year 2022\n",
      "Fetching data for state 50 for year 2022\n",
      "Finished data for year 2022\n",
      "Fetching data for state 01 for year 2023\n",
      "Fetching data for state 02 for year 2023\n",
      "Fetching data for state 03 for year 2023\n",
      "Fetching data for state 04 for year 2023\n",
      "Fetching data for state 05 for year 2023\n",
      "Fetching data for state 06 for year 2023\n",
      "Fetching data for state 07 for year 2023\n",
      "Fetching data for state 08 for year 2023\n",
      "Fetching data for state 09 for year 2023\n",
      "Fetching data for state 10 for year 2023\n",
      "Fetching data for state 11 for year 2023\n",
      "Fetching data for state 12 for year 2023\n",
      "Fetching data for state 13 for year 2023\n",
      "Fetching data for state 14 for year 2023\n",
      "Fetching data for state 15 for year 2023\n",
      "Fetching data for state 16 for year 2023\n",
      "Fetching data for state 17 for year 2023\n",
      "Fetching data for state 18 for year 2023\n",
      "Fetching data for state 19 for year 2023\n",
      "Fetching data for state 20 for year 2023\n",
      "Fetching data for state 21 for year 2023\n",
      "Fetching data for state 22 for year 2023\n",
      "Fetching data for state 23 for year 2023\n",
      "Fetching data for state 24 for year 2023\n",
      "Fetching data for state 25 for year 2023\n",
      "Fetching data for state 26 for year 2023\n",
      "Fetching data for state 27 for year 2023\n",
      "Fetching data for state 28 for year 2023\n",
      "Fetching data for state 29 for year 2023\n",
      "Fetching data for state 30 for year 2023\n",
      "Fetching data for state 31 for year 2023\n",
      "Fetching data for state 32 for year 2023\n",
      "Fetching data for state 33 for year 2023\n",
      "Fetching data for state 34 for year 2023\n",
      "Fetching data for state 35 for year 2023\n",
      "Fetching data for state 36 for year 2023\n",
      "Fetching data for state 37 for year 2023\n",
      "Fetching data for state 38 for year 2023\n",
      "Fetching data for state 39 for year 2023\n",
      "Fetching data for state 40 for year 2023\n",
      "Fetching data for state 41 for year 2023\n",
      "Fetching data for state 42 for year 2023\n",
      "Fetching data for state 43 for year 2023\n",
      "Fetching data for state 44 for year 2023\n",
      "Fetching data for state 45 for year 2023\n",
      "Fetching data for state 46 for year 2023\n",
      "Fetching data for state 47 for year 2023\n",
      "Fetching data for state 48 for year 2023\n",
      "Fetching data for state 49 for year 2023\n",
      "Fetching data for state 50 for year 2023\n",
      "Finished data for year 2023\n"
     ]
    }
   ],
   "source": [
    "# Set Parameters\n",
    "param = \"42101\"  # Carbon Monoxide\n",
    "selected_columns = [\n",
    "    'date_local', 'parameter', 'aqi', 'arithmetic_mean', 'first_max_value', 'observation_count', \n",
    "    'observation_percent'    \n",
    "    ]\n",
    "state_codes = [\n",
    "    '01', '02', '03', '04', '05', '06', '07', '08', '09', '10',\n",
    "    '11', '12', '13', '14', '15', '16', '17', '18', '19', '20',\n",
    "    '21', '22', '23', '24', '25', '26', '27', '28', '29', '30',\n",
    "    '31', '32', '33', '34', '35', '36', '37', '38', '39', '40',\n",
    "    '41', '42', '43', '44', '45', '46', '47', '48', '49', '50'\n",
    "] # All states\n",
    "\n",
    "# Get years 2017-2023\n",
    "years = [\"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "\n",
    "weekly_emissions_all_years = pd.DataFrame()\n",
    "daily_emissions_all_years = pd.DataFrame()\n",
    "for year in years:\n",
    "    bdate = year + \"0101\"\n",
    "    edate = year + \"1231\"\n",
    "\n",
    "    all_states_data = []\n",
    "    for state_code in state_codes:\n",
    "        data = fetch_data_for_state(state_code, param, bdate, edate)\n",
    "        print(f\"Fetching data for state {state_code} for year {year}\")\n",
    "        # Check if data is not null and contains key 'Data', if so then add to list of data\n",
    "        if data and 'Data' in data: \n",
    "            all_states_data.extend(data['Data'])\n",
    "        \n",
    "    df = pd.DataFrame(all_states_data) # Convert to pandas DataFrame\n",
    "    daily_emissions_all_years = pd.concat([daily_emissions_all_years, df], ignore_index=True) # Add to the main dataframe\n",
    "    print(f\"Finished data for year {year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "weekly_emissions_all_years = clean_emissions_data(daily_emissions_all_years, selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good.. lets check what features we got from our request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 358 entries, 0 to 357\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date_local           358 non-null    datetime64[ns]\n",
      " 1   aqi                  358 non-null    float64       \n",
      " 2   arithmetic_mean      358 non-null    float64       \n",
      " 3   first_max_value      358 non-null    float64       \n",
      " 4   observation_count    358 non-null    float64       \n",
      " 5   observation_percent  358 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(5)\n",
      "memory usage: 16.9 KB\n"
     ]
    }
   ],
   "source": [
    "weekly_emissions_all_years.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_local</th>\n",
       "      <th>aqi</th>\n",
       "      <th>arithmetic_mean</th>\n",
       "      <th>first_max_value</th>\n",
       "      <th>observation_count</th>\n",
       "      <th>observation_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>5.2537</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.5490</td>\n",
       "      <td>21.4296</td>\n",
       "      <td>87.2596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>5.3433</td>\n",
       "      <td>0.3353</td>\n",
       "      <td>0.5320</td>\n",
       "      <td>24.0056</td>\n",
       "      <td>98.0167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>5.6162</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.5615</td>\n",
       "      <td>24.0184</td>\n",
       "      <td>98.0976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>5.0476</td>\n",
       "      <td>0.2946</td>\n",
       "      <td>0.4908</td>\n",
       "      <td>24.0804</td>\n",
       "      <td>98.3656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>5.4081</td>\n",
       "      <td>0.3288</td>\n",
       "      <td>0.5538</td>\n",
       "      <td>24.0697</td>\n",
       "      <td>98.3138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-02-05</td>\n",
       "      <td>4.9927</td>\n",
       "      <td>0.3165</td>\n",
       "      <td>0.4877</td>\n",
       "      <td>24.1107</td>\n",
       "      <td>98.5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>5.0849</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.4856</td>\n",
       "      <td>24.0276</td>\n",
       "      <td>98.1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-02-19</td>\n",
       "      <td>4.7815</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>0.4717</td>\n",
       "      <td>24.1220</td>\n",
       "      <td>98.5176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-02-26</td>\n",
       "      <td>3.8364</td>\n",
       "      <td>0.2428</td>\n",
       "      <td>0.3860</td>\n",
       "      <td>24.1132</td>\n",
       "      <td>98.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-03-05</td>\n",
       "      <td>3.7852</td>\n",
       "      <td>0.2457</td>\n",
       "      <td>0.3722</td>\n",
       "      <td>24.1534</td>\n",
       "      <td>98.6470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_local     aqi  arithmetic_mean  first_max_value  observation_count  \\\n",
       "0 2017-01-01  5.2537           0.3205           0.5490            21.4296   \n",
       "1 2017-01-08  5.3433           0.3353           0.5320            24.0056   \n",
       "2 2017-01-15  5.6162           0.3451           0.5615            24.0184   \n",
       "3 2017-01-22  5.0476           0.2946           0.4908            24.0804   \n",
       "4 2017-01-29  5.4081           0.3288           0.5538            24.0697   \n",
       "5 2017-02-05  4.9927           0.3165           0.4877            24.1107   \n",
       "6 2017-02-12  5.0849           0.2977           0.4856            24.0276   \n",
       "7 2017-02-19  4.7815           0.2906           0.4717            24.1220   \n",
       "8 2017-02-26  3.8364           0.2428           0.3860            24.1132   \n",
       "9 2017-03-05  3.7852           0.2457           0.3722            24.1534   \n",
       "\n",
       "   observation_percent  \n",
       "0              87.2596  \n",
       "1              98.0167  \n",
       "2              98.0976  \n",
       "3              98.3656  \n",
       "4              98.3138  \n",
       "5              98.5082  \n",
       "6              98.1360  \n",
       "7              98.5176  \n",
       "8              98.4750  \n",
       "9              98.6470  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_emissions_all_years.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final df to csv\n",
    "weekly_emissions_all_years.to_csv(\"emissions_data_2017_2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_emissions_all_years.to_csv(\"detailed_emissions_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
